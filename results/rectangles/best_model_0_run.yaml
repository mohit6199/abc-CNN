backend: tensorflow
class_name: Sequential
config:
  layers:
  - class_name: Conv2D
    config:
      activation: linear
      activity_regularizer: null
      batch_input_shape: !!python/tuple [null, 28, 28, 1]
      bias_constraint: null
      bias_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      bias_regularizer: null
      data_format: channels_last
      dilation_rate: &id001 !!python/tuple [1, 1]
      dtype: float32
      filters: 204
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      kernel_size: !!python/tuple [6, 6]
      name: conv2d_688
      padding: same
      strides: !!python/tuple [1, 1]
      trainable: true
      use_bias: true
  - class_name: BatchNormalization
    config:
      axis: -1
      beta_constraint: null
      beta_initializer:
        class_name: Zeros
        config: {}
      beta_regularizer: null
      center: true
      dtype: float32
      epsilon: 0.001
      gamma_constraint: null
      gamma_initializer:
        class_name: Ones
        config: {}
      gamma_regularizer: null
      momentum: 0.99
      moving_mean_initializer:
        class_name: Zeros
        config: {}
      moving_variance_initializer:
        class_name: Ones
        config: {}
      name: batch_normalization_1163
      scale: true
      trainable: true
  - class_name: Activation
    config: {activation: relu, dtype: float32, name: activation_1163, trainable: true}
  - class_name: Dropout
    config: {dtype: float32, name: dropout_951, noise_shape: null, rate: 0.5, seed: null,
      trainable: true}
  - class_name: Conv2D
    config:
      activation: linear
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      bias_regularizer: null
      data_format: channels_last
      dilation_rate: *id001
      dtype: float32
      filters: 149
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      kernel_size: !!python/tuple [3, 3]
      name: conv2d_689
      padding: same
      strides: &id002 !!python/tuple [1, 1]
      trainable: true
      use_bias: true
  - class_name: BatchNormalization
    config:
      axis: -1
      beta_constraint: null
      beta_initializer:
        class_name: Zeros
        config: {}
      beta_regularizer: null
      center: true
      dtype: float32
      epsilon: 0.001
      gamma_constraint: null
      gamma_initializer:
        class_name: Ones
        config: {}
      gamma_regularizer: null
      momentum: 0.99
      moving_mean_initializer:
        class_name: Zeros
        config: {}
      moving_variance_initializer:
        class_name: Ones
        config: {}
      name: batch_normalization_1164
      scale: true
      trainable: true
  - class_name: Activation
    config: {activation: relu, dtype: float32, name: activation_1164, trainable: true}
  - class_name: Dropout
    config: {dtype: float32, name: dropout_952, noise_shape: null, rate: 0.5, seed: null,
      trainable: true}
  - class_name: Conv2D
    config:
      activation: linear
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      bias_regularizer: null
      data_format: channels_last
      dilation_rate: *id001
      dtype: float32
      filters: 44
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      kernel_size: !!python/tuple [5, 5]
      name: conv2d_690
      padding: same
      strides: *id002
      trainable: true
      use_bias: true
  - class_name: BatchNormalization
    config:
      axis: -1
      beta_constraint: null
      beta_initializer:
        class_name: Zeros
        config: {}
      beta_regularizer: null
      center: true
      dtype: float32
      epsilon: 0.001
      gamma_constraint: null
      gamma_initializer:
        class_name: Ones
        config: {}
      gamma_regularizer: null
      momentum: 0.99
      moving_mean_initializer:
        class_name: Zeros
        config: {}
      moving_variance_initializer:
        class_name: Ones
        config: {}
      name: batch_normalization_1165
      scale: true
      trainable: true
  - class_name: Activation
    config: {activation: relu, dtype: float32, name: activation_1165, trainable: true}
  - class_name: Flatten
    config: {data_format: channels_last, dtype: float32, name: flatten_213, trainable: true}
  - class_name: Dropout
    config: {dtype: float32, name: dropout_953, noise_shape: null, rate: 0.5, seed: null,
      trainable: true}
  - class_name: Dense
    config:
      activation: linear
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      bias_regularizer: null
      dtype: float32
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      name: dense_476
      trainable: true
      units: 2
      use_bias: true
  - class_name: BatchNormalization
    config:
      axis: -1
      beta_constraint: null
      beta_initializer:
        class_name: Zeros
        config: {}
      beta_regularizer: null
      center: true
      dtype: float32
      epsilon: 0.001
      gamma_constraint: null
      gamma_initializer:
        class_name: Ones
        config: {}
      gamma_regularizer: null
      momentum: 0.99
      moving_mean_initializer:
        class_name: Zeros
        config: {}
      moving_variance_initializer:
        class_name: Ones
        config: {}
      name: batch_normalization_1166
      scale: true
      trainable: true
  - class_name: Activation
    config: {activation: softmax, dtype: float32, name: activation_1166, trainable: true}
  name: sequential_213
keras_version: 2.3.1
