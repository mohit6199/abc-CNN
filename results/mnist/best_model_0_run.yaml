backend: tensorflow
class_name: Sequential
config:
  layers:
  - class_name: Conv2D
    config:
      activation: linear
      activity_regularizer: null
      batch_input_shape: !!python/tuple [null, 28, 28, 1]
      bias_constraint: null
      bias_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      bias_regularizer: null
      data_format: channels_last
      dilation_rate: &id001 !!python/tuple [1, 1]
      dtype: float32
      filters: 242
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      kernel_size: !!python/tuple [3, 3]
      name: conv2d_358
      padding: same
      strides: !!python/tuple [1, 1]
      trainable: true
      use_bias: true
  - class_name: BatchNormalization
    config:
      axis: -1
      beta_constraint: null
      beta_initializer:
        class_name: Zeros
        config: {}
      beta_regularizer: null
      center: true
      dtype: float32
      epsilon: 0.001
      gamma_constraint: null
      gamma_initializer:
        class_name: Ones
        config: {}
      gamma_regularizer: null
      momentum: 0.99
      moving_mean_initializer:
        class_name: Zeros
        config: {}
      moving_variance_initializer:
        class_name: Ones
        config: {}
      name: batch_normalization_626
      scale: true
      trainable: true
  - class_name: Activation
    config: {activation: relu, dtype: float32, name: activation_626, trainable: true}
  - class_name: Dropout
    config: {dtype: float32, name: dropout_518, noise_shape: null, rate: 0.5, seed: null,
      trainable: true}
  - class_name: Conv2D
    config:
      activation: linear
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      bias_regularizer: null
      data_format: channels_last
      dilation_rate: *id001
      dtype: float32
      filters: 189
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      kernel_size: !!python/tuple [6, 6]
      name: conv2d_359
      padding: same
      strides: &id002 !!python/tuple [1, 1]
      trainable: true
      use_bias: true
  - class_name: BatchNormalization
    config:
      axis: -1
      beta_constraint: null
      beta_initializer:
        class_name: Zeros
        config: {}
      beta_regularizer: null
      center: true
      dtype: float32
      epsilon: 0.001
      gamma_constraint: null
      gamma_initializer:
        class_name: Ones
        config: {}
      gamma_regularizer: null
      momentum: 0.99
      moving_mean_initializer:
        class_name: Zeros
        config: {}
      moving_variance_initializer:
        class_name: Ones
        config: {}
      name: batch_normalization_627
      scale: true
      trainable: true
  - class_name: Activation
    config: {activation: relu, dtype: float32, name: activation_627, trainable: true}
  - class_name: Dropout
    config: {dtype: float32, name: dropout_519, noise_shape: null, rate: 0.5, seed: null,
      trainable: true}
  - class_name: Conv2D
    config:
      activation: linear
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      bias_regularizer: null
      data_format: channels_last
      dilation_rate: *id001
      dtype: float32
      filters: 55
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      kernel_size: !!python/tuple [6, 6]
      name: conv2d_360
      padding: same
      strides: *id002
      trainable: true
      use_bias: true
  - class_name: BatchNormalization
    config:
      axis: -1
      beta_constraint: null
      beta_initializer:
        class_name: Zeros
        config: {}
      beta_regularizer: null
      center: true
      dtype: float32
      epsilon: 0.001
      gamma_constraint: null
      gamma_initializer:
        class_name: Ones
        config: {}
      gamma_regularizer: null
      momentum: 0.99
      moving_mean_initializer:
        class_name: Zeros
        config: {}
      moving_variance_initializer:
        class_name: Ones
        config: {}
      name: batch_normalization_628
      scale: true
      trainable: true
  - class_name: Activation
    config: {activation: relu, dtype: float32, name: activation_628, trainable: true}
  - class_name: Dropout
    config: {dtype: float32, name: dropout_520, noise_shape: null, rate: 0.5, seed: null,
      trainable: true}
  - class_name: Conv2D
    config:
      activation: linear
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      bias_regularizer: null
      data_format: channels_last
      dilation_rate: *id001
      dtype: float32
      filters: 236
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      kernel_size: !!python/tuple [3, 3]
      name: conv2d_361
      padding: same
      strides: *id002
      trainable: true
      use_bias: true
  - class_name: BatchNormalization
    config:
      axis: -1
      beta_constraint: null
      beta_initializer:
        class_name: Zeros
        config: {}
      beta_regularizer: null
      center: true
      dtype: float32
      epsilon: 0.001
      gamma_constraint: null
      gamma_initializer:
        class_name: Ones
        config: {}
      gamma_regularizer: null
      momentum: 0.99
      moving_mean_initializer:
        class_name: Zeros
        config: {}
      moving_variance_initializer:
        class_name: Ones
        config: {}
      name: batch_normalization_629
      scale: true
      trainable: true
  - class_name: Activation
    config: {activation: relu, dtype: float32, name: activation_629, trainable: true}
  - class_name: Dropout
    config: {dtype: float32, name: dropout_521, noise_shape: null, rate: 0.5, seed: null,
      trainable: true}
  - class_name: Conv2D
    config:
      activation: linear
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      bias_regularizer: null
      data_format: channels_last
      dilation_rate: *id001
      dtype: float32
      filters: 196
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      kernel_size: !!python/tuple [6, 6]
      name: conv2d_362
      padding: same
      strides: *id002
      trainable: true
      use_bias: true
  - class_name: BatchNormalization
    config:
      axis: -1
      beta_constraint: null
      beta_initializer:
        class_name: Zeros
        config: {}
      beta_regularizer: null
      center: true
      dtype: float32
      epsilon: 0.001
      gamma_constraint: null
      gamma_initializer:
        class_name: Ones
        config: {}
      gamma_regularizer: null
      momentum: 0.99
      moving_mean_initializer:
        class_name: Zeros
        config: {}
      moving_variance_initializer:
        class_name: Ones
        config: {}
      name: batch_normalization_630
      scale: true
      trainable: true
  - class_name: Activation
    config: {activation: relu, dtype: float32, name: activation_630, trainable: true}
  - class_name: Flatten
    config: {data_format: channels_last, dtype: float32, name: flatten_109, trainable: true}
  - class_name: Dropout
    config: {dtype: float32, name: dropout_522, noise_shape: null, rate: 0.5, seed: null,
      trainable: true}
  - class_name: Dense
    config:
      activation: linear
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      bias_regularizer: null
      dtype: float32
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      name: dense_269
      trainable: true
      units: 10
      use_bias: true
  - class_name: BatchNormalization
    config:
      axis: -1
      beta_constraint: null
      beta_initializer:
        class_name: Zeros
        config: {}
      beta_regularizer: null
      center: true
      dtype: float32
      epsilon: 0.001
      gamma_constraint: null
      gamma_initializer:
        class_name: Ones
        config: {}
      gamma_regularizer: null
      momentum: 0.99
      moving_mean_initializer:
        class_name: Zeros
        config: {}
      moving_variance_initializer:
        class_name: Ones
        config: {}
      name: batch_normalization_631
      scale: true
      trainable: true
  - class_name: Activation
    config: {activation: softmax, dtype: float32, name: activation_631, trainable: true}
  name: sequential_109
keras_version: 2.3.1
